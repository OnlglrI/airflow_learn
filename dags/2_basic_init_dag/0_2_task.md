## Задачи (Tasks)

**Задача (Task)** — это базовая единица выполнения в Airflow. Задачи объединяются в DAG’и, а между ними задаются зависимости upstream и downstream, чтобы определить порядок их выполнения.

Существует три основных типа задач:

* **Операторы (Operators)** — предопределённые шаблоны задач, которые можно быстро связать между собой для построения большинства частей DAG’ов.
* **Сенсоры (Sensors)** — специальный подкласс операторов, предназначенный исключительно для ожидания наступления внешнего события.
* **TaskFlow-задачи с декоратором `@task`** — пользовательские Python-функции, упакованные в виде задачи.

Внутренне все они являются подклассами `BaseOperator` Airflow, и понятия *Task* и *Operator* в некоторой степени взаимозаменяемы. Тем не менее, полезно разделять эти понятия: **операторы и сенсоры — это шаблоны**, а **когда вы вызываете их в файле DAG, вы создаёте задачу (Task)**.

---

## Связи между задачами (Relationships)

Ключевая часть работы с задачами — это определение их взаимосвязей, то есть зависимостей. В терминологии Airflow это upstream и downstream задачи. Сначала вы объявляете задачи, а затем — их зависимости.

### Примечание

Upstream-задачей называется задача, которая непосредственно предшествует другой задаче. Ранее она называлась *parent task*. Важно понимать, что этот термин **не описывает иерархию DAG целиком** — upstream-задача не обязательно является «родительской» в иерархическом смысле. То же самое относится и к downstream-задачам — они должны быть **непосредственно** связаны с текущей задачей.

---

### Способы задания зависимостей

Существует два способа задания зависимостей.

#### 1. С помощью операторов `>>` и `<<` (bitshift-операторы):

```python
first_task >> second_task >> [third_task, fourth_task]
```

#### 2. С помощью явных методов `set_upstream` и `set_downstream`:

```python
first_task.set_downstream(second_task)
third_task.set_upstream(second_task)
```

Оба способа делают одно и то же, но **рекомендуется использовать bitshift-операторы**, так как они обычно читаются проще и нагляднее.

---

По умолчанию задача запускается тогда, когда **все её upstream-задачи успешно завершены**. 

Задачи **не передают данные друг другу по умолчанию** и выполняются полностью независимо. Если требуется передача информации от одной задачи к другой, следует использовать **XCom**.

---

## Экземпляры задач (Task Instances)

Аналогично тому, как DAG при каждом запуске создаёт **Dag Run**, задачи внутри DAG создают **экземпляры задач (Task Instance)**.

Экземпляр задачи — это конкретный запуск задачи для определённого DAG (и, соответственно, для конкретного временного интервала данных). Экземпляры задач также хранят состояние, отражающее этап жизненного цикла задачи.

---

### Возможные состояния Task Instance:

* **none** — задача ещё не поставлена в очередь на выполнение (зависимости не выполнены)
* **scheduled** — планировщик определил, что зависимости выполнены, и задачу можно запускать
* **queued** — задача передана исполнителю (Executor) и ожидает воркер
* **running** — задача выполняется на воркере (или локальном/синхронном executor’е)
* **success** — задача успешно завершилась без ошибок
* **restarting** — для задачи был запрошен перезапуск во время выполнения
* **failed** — задача завершилась с ошибкой
* **skipped** — задача была пропущена из-за ветвления, `LatestOnly` или аналогичных механизмов
* **upstream_failed** — upstream-задача завершилась с ошибкой, и trigger rule требует её успешного выполнения
* **up_for_retry** — задача завершилась с ошибкой, но у неё остались попытки повторного выполнения
* **up_for_reschedule** — задача-сенсор работает в режиме reschedule
* **deferred** — задача была отложена до срабатывания триггера
* **removed** — задача исчезла из DAG после начала запуска
![](../../img/task/diagram_task_lifecycle.png)
Идеальный жизненный цикл задачи:
**none → scheduled → queued → running → success**

---

Когда пользовательская задача (оператор) выполняется, ей передаётся объект `TaskInstance`. Через него можно читать метаданные задачи, а также использовать методы для работы с XCom.

---

## Терминология связей (Relationship Terminology)

Для любого экземпляра задачи существуют два типа связей с другими экземплярами.

### Upstream / Downstream

```python
task1 >> task2 >> task3
```

При запуске DAG создаются экземпляры всех этих задач, которые являются upstream/downstream друг для друга и относятся к **одному и тому же интервалу данных**.

### Previous / Next

Также могут существовать экземпляры **одной и той же задачи**, но для **разных интервалов данных** (разные запуски DAG). Такие связи называются **previous** и **next** и **не являются upstream/downstream**.


---

## Тайм-ауты (Timeouts)

Если вы хотите задать максимальное время выполнения задачи, используйте параметр `execution_timeout`, установив его в `datetime.timedelta`. Это применимо ко всем задачам Airflow, включая сенсоры.

`execution_timeout` определяет **максимально допустимое время одного выполнения**. Если оно превышено, задача завершается с ошибкой `AirflowTaskTimeout`.

---

### Тайм-ауты сенсоров

У сенсоров есть дополнительный параметр `timeout`. Он применяется **только в режиме reschedule**.

* `execution_timeout` — ограничивает время одного запуска сенсора
* `timeout` — ограничивает **общее время ожидания события**

Если `timeout` превышен, возникает исключение `AirflowSensorTimeout`, и сенсор **не повторяется**.

---

### Пример SFTPSensor

Сенсор работает в режиме `reschedule`, то есть периодически выполняется и переходит в ожидание до успеха.

* Каждый запрос к SFTP-серверу может длиться максимум 60 секунд (`execution_timeout`)
* Сенсор может повториться до 2 раз (`retries`)
* Общее время ожидания появления файла — максимум 3600 секунд (`timeout`)

Если файл не появился за 3600 секунд, сенсор завершается с `AirflowSensorTimeout` без повторных попыток.

```python
sensor = SFTPSensor(
    task_id="sensor",
    path="/root/test",
    execution_timeout=timedelta(seconds=60),
    timeout=3600,
    retries=2,
    mode="reschedule",
)
```

---

## Специальные исключения (Special Exceptions)

Для управления состоянием задачи из пользовательского кода Airflow предоставляет два специальных исключения:

* `AirflowSkipException` — помечает задачу как *skipped*
* `AirflowFailException` — помечает задачу как *failed*, игнорируя оставшиеся попытки

Это полезно, если код знает о ситуации больше, чем планировщик (например, данных нет — можно сразу пропустить задачу).

---

## Тайм-аут heartbeat Task Instance

Иногда Task Instance может «зависнуть» в состоянии `running`, несмотря на то, что связанный процесс уже не активен (например, воркер был убит из-за нехватки памяти). Такие задачи ранее назывались *zombie tasks*.

Airflow периодически обнаруживает такие ситуации, очищает их и помечает задачу как failed или retry.

Причины heartbeat timeout могут быть следующими:

* воркер был убит из-за нехватки памяти (OOMKilled)
* воркер не прошёл liveness-probe (например, в Kubernetes)
* система переместила воркер на другой узел

---

### Воспроизведение heartbeat timeout локально

Установите переменные окружения:

```bash
export AIRFLOW__SCHEDULER__TASK_INSTANCE_HEARTBEAT_SEC=600
export AIRFLOW__SCHEDULER__TASK_INSTANCE_HEARTBEAT_TIMEOUT=2
export AIRFLOW__SCHEDULER__TASK_INSTANCE_HEARTBEAT_TIMEOUT_DETECTION_INTERVAL=5
```

Создайте DAG с долгой задачей (например, 10 минут):

```python
from airflow.sdk import dag
from airflow.providers.standard.operators.bash import BashOperator
from datetime import datetime

@dag(start_date=datetime(2021, 1, 1), schedule="@once", catchup=False)
def sleep_dag():
    t1 = BashOperator(
        task_id="sleep_10_minutes",
        bash_command="sleep 600",
    )

sleep_dag()
```

После запуска DAG задача будет помечена как failed через `<task_instance_heartbeat_timeout>` секунд.

---

[Источник](https://airflow.apache.org/docs/apache-airflow/stable/core-concepts/tasks.html#)